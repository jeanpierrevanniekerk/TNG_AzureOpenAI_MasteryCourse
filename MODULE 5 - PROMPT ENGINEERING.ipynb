{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08be7e42-f69f-492b-bdff-d8331f5e8be7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting azure-identity==1.6.0\r\n  Using cached azure_identity-1.6.0-py2.py3-none-any.whl (108 kB)\r\nCollecting streamlit==1.18.1\r\n  Using cached streamlit-1.18.1-py2.py3-none-any.whl (9.6 MB)\r\nCollecting openai==0.27.8\r\n  Using cached openai-0.27.8-py3-none-any.whl (73 kB)\r\nCollecting python-dotenv==0.21.0\r\n  Using cached python_dotenv-0.21.0-py3-none-any.whl (18 kB)\r\nRequirement already satisfied: numpy in /databricks/python3/lib/python3.10/site-packages (from -r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 5)) (1.21.5)\r\nRequirement already satisfied: pandas in /databricks/python3/lib/python3.10/site-packages (from -r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 6)) (1.4.4)\r\nCollecting matplotlib==3.6.3\r\n  Using cached matplotlib-3.6.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.8 MB)\r\nCollecting plotly==5.12.0\r\n  Using cached plotly-5.12.0-py2.py3-none-any.whl (15.2 MB)\r\nCollecting scipy==1.10.0\r\n  Using cached scipy-1.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.4 MB)\r\nCollecting scikit-learn==1.2.0\r\n  Using cached scikit_learn-1.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.5 MB)\r\nRequirement already satisfied: tenacity in /databricks/python3/lib/python3.10/site-packages (from -r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 11)) (8.1.0)\r\nCollecting tiktoken==0.3.0\r\n  Using cached tiktoken-0.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\r\nCollecting llama-index==0.4.33\r\n  Using cached llama_index-0.4.33-py3-none-any.whl\r\nCollecting langchain==0.0.129\r\n  Using cached langchain-0.0.129-py3-none-any.whl (467 kB)\r\nCollecting faiss-cpu\r\n  Using cached faiss_cpu-1.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\r\nCollecting msal<2.0.0,>=1.7.0\r\n  Using cached msal-1.23.0-py2.py3-none-any.whl (90 kB)\r\nRequirement already satisfied: azure-core<2.0.0,>=1.0.0 in /databricks/python3/lib/python3.10/site-packages (from azure-identity==1.6.0->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 1)) (1.27.1)\r\nRequirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from azure-identity==1.6.0->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 1)) (1.16.0)\r\nCollecting msal-extensions~=0.3.0\r\n  Using cached msal_extensions-0.3.1-py2.py3-none-any.whl (18 kB)\r\nRequirement already satisfied: cryptography>=2.1.4 in /databricks/python3/lib/python3.10/site-packages (from azure-identity==1.6.0->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 1)) (37.0.1)\r\nRequirement already satisfied: python-dateutil in /databricks/python3/lib/python3.10/site-packages (from streamlit==1.18.1->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 2)) (2.8.2)\r\nRequirement already satisfied: tornado>=6.0.3 in /databricks/python3/lib/python3.10/site-packages (from streamlit==1.18.1->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 2)) (6.1)\r\nRequirement already satisfied: requests>=2.4 in /databricks/python3/lib/python3.10/site-packages (from streamlit==1.18.1->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 2)) (2.28.1)\r\nRequirement already satisfied: protobuf<4,>=3.12 in /databricks/python3/lib/python3.10/site-packages (from streamlit==1.18.1->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 2)) (3.19.4)\r\nCollecting validators>=0.2\r\n  Using cached validators-0.21.2-py3-none-any.whl (25 kB)\r\nCollecting rich>=10.11.0\r\n  Using cached rich-13.5.2-py3-none-any.whl (239 kB)\r\nCollecting toml\r\n  Using cached toml-0.10.2-py2.py3-none-any.whl (16 kB)\r\nRequirement already satisfied: pyarrow>=4.0 in /databricks/python3/lib/python3.10/site-packages (from streamlit==1.18.1->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 2)) (8.0.0)\r\nRequirement already satisfied: cachetools>=4.0 in /databricks/python3/lib/python3.10/site-packages (from streamlit==1.18.1->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 2)) (4.2.4)\r\nRequirement already satisfied: packaging>=14.1 in /databricks/python3/lib/python3.10/site-packages (from streamlit==1.18.1->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 2)) (21.3)\r\nCollecting watchdog\r\n  Using cached watchdog-3.0.0-py3-none-manylinux2014_x86_64.whl (82 kB)\r\nRequirement already satisfied: gitpython!=3.1.19 in /databricks/python3/lib/python3.10/site-packages (from streamlit==1.18.1->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 2)) (3.1.27)\r\nRequirement already satisfied: importlib-metadata>=1.4 in /databricks/python3/lib/python3.10/site-packages (from streamlit==1.18.1->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 2)) (4.11.3)\r\nRequirement already satisfied: click>=7.0 in /databricks/python3/lib/python3.10/site-packages (from streamlit==1.18.1->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 2)) (8.0.4)\r\nCollecting tzlocal>=1.1\r\n  Using cached tzlocal-5.0.1-py3-none-any.whl (20 kB)\r\nRequirement already satisfied: blinker>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit==1.18.1->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 2)) (1.4)\r\nCollecting semver\r\n  Using cached semver-3.0.1-py3-none-any.whl (17 kB)\r\nRequirement already satisfied: typing-extensions>=3.10.0.0 in /databricks/python3/lib/python3.10/site-packages (from streamlit==1.18.1->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 2)) (4.3.0)\r\nRequirement already satisfied: pillow>=6.2.0 in /databricks/python3/lib/python3.10/site-packages (from streamlit==1.18.1->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 2)) (9.2.0)\r\nCollecting pympler>=0.9\r\n  Using cached Pympler-1.0.1-py3-none-any.whl (164 kB)\r\nCollecting altair>=3.2.0\r\n  Using cached altair-5.1.1-py3-none-any.whl (520 kB)\r\nCollecting pydeck>=0.1.dev5\r\n  Using cached pydeck-0.8.1b0-py2.py3-none-any.whl (4.8 MB)\r\nRequirement already satisfied: tqdm in /databricks/python3/lib/python3.10/site-packages (from openai==0.27.8->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 3)) (4.64.1)\r\nRequirement already satisfied: aiohttp in /databricks/python3/lib/python3.10/site-packages (from openai==0.27.8->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 3)) (3.8.4)\r\nRequirement already satisfied: kiwisolver>=1.0.1 in /databricks/python3/lib/python3.10/site-packages (from matplotlib==3.6.3->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 7)) (1.4.2)\r\nRequirement already satisfied: cycler>=0.10 in /databricks/python3/lib/python3.10/site-packages (from matplotlib==3.6.3->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 7)) (0.11.0)\r\nRequirement already satisfied: pyparsing>=2.2.1 in /databricks/python3/lib/python3.10/site-packages (from matplotlib==3.6.3->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 7)) (3.0.9)\r\nCollecting contourpy>=1.0.1\r\n  Using cached contourpy-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB)\r\nRequirement already satisfied: fonttools>=4.22.0 in /databricks/python3/lib/python3.10/site-packages (from matplotlib==3.6.3->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 7)) (4.25.0)\r\nRequirement already satisfied: joblib>=1.1.1 in /databricks/python3/lib/python3.10/site-packages (from scikit-learn==1.2.0->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 10)) (1.2.0)\r\nRequirement already satisfied: threadpoolctl>=2.0.0 in /databricks/python3/lib/python3.10/site-packages (from scikit-learn==1.2.0->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 10)) (2.2.0)\r\nCollecting blobfile>=2\r\n  Using cached blobfile-2.0.2-py3-none-any.whl (74 kB)\r\nRequirement already satisfied: regex>=2022.1.18 in /databricks/python3/lib/python3.10/site-packages (from tiktoken==0.3.0->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 12)) (2022.7.9)\r\nCollecting tenacity\r\n  Using cached tenacity-8.2.3-py3-none-any.whl (24 kB)\r\nRequirement already satisfied: dataclasses-json in /databricks/python3/lib/python3.10/site-packages (from llama-index==0.4.33->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 13)) (0.5.8)\r\nRequirement already satisfied: SQLAlchemy<2,>=1 in /databricks/python3/lib/python3.10/site-packages (from langchain==0.0.129->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 14)) (1.4.39)\r\nRequirement already satisfied: PyYAML>=5.4.1 in /databricks/python3/lib/python3.10/site-packages (from langchain==0.0.129->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 14)) (6.0)\r\nRequirement already satisfied: pydantic<2,>=1 in /databricks/python3/lib/python3.10/site-packages (from langchain==0.0.129->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 14)) (1.10.6)\r\nRequirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.10/site-packages (from pandas->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 6)) (2022.1)\r\nRequirement already satisfied: attrs>=17.3.0 in /databricks/python3/lib/python3.10/site-packages (from aiohttp->openai==0.27.8->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 3)) (21.4.0)\r\nRequirement already satisfied: yarl<2.0,>=1.0 in /databricks/python3/lib/python3.10/site-packages (from aiohttp->openai==0.27.8->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 3)) (1.9.2)\r\nRequirement already satisfied: multidict<7.0,>=4.5 in /databricks/python3/lib/python3.10/site-packages (from aiohttp->openai==0.27.8->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 3)) (6.0.4)\r\nRequirement already satisfied: frozenlist>=1.1.1 in /databricks/python3/lib/python3.10/site-packages (from aiohttp->openai==0.27.8->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 3)) (1.3.3)\r\nRequirement already satisfied: aiosignal>=1.1.2 in /databricks/python3/lib/python3.10/site-packages (from aiohttp->openai==0.27.8->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 3)) (1.3.1)\r\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /databricks/python3/lib/python3.10/site-packages (from aiohttp->openai==0.27.8->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 3)) (4.0.2)\r\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /databricks/python3/lib/python3.10/site-packages (from aiohttp->openai==0.27.8->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 3)) (2.0.4)\r\nRequirement already satisfied: jsonschema>=3.0 in /databricks/python3/lib/python3.10/site-packages (from altair>=3.2.0->streamlit==1.18.1->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 2)) (4.16.0)\r\nCollecting toolz\r\n  Using cached toolz-0.12.0-py3-none-any.whl (55 kB)\r\nRequirement already satisfied: jinja2 in /databricks/python3/lib/python3.10/site-packages (from altair>=3.2.0->streamlit==1.18.1->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 2)) (2.11.3)\r\nRequirement already satisfied: filelock~=3.0 in /databricks/python3/lib/python3.10/site-packages (from blobfile>=2->tiktoken==0.3.0->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 12)) (3.6.0)\r\nRequirement already satisfied: urllib3<3,>=1.25.3 in /databricks/python3/lib/python3.10/site-packages (from blobfile>=2->tiktoken==0.3.0->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 12)) (1.26.11)\r\nCollecting pycryptodomex~=3.8\r\n  Using cached pycryptodomex-3.18.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\r\nCollecting lxml~=4.9\r\n  Using cached lxml-4.9.3-cp310-cp310-manylinux_2_28_x86_64.whl (7.9 MB)\r\nRequirement already satisfied: cffi>=1.12 in /databricks/python3/lib/python3.10/site-packages (from cryptography>=2.1.4->azure-identity==1.6.0->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 1)) (1.15.1)\r\nRequirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /databricks/python3/lib/python3.10/site-packages (from dataclasses-json->llama-index==0.4.33->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 13)) (1.5.1)\r\nRequirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /databricks/python3/lib/python3.10/site-packages (from dataclasses-json->llama-index==0.4.33->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 13)) (3.19.0)\r\nRequirement already satisfied: typing-inspect>=0.4.0 in /databricks/python3/lib/python3.10/site-packages (from dataclasses-json->llama-index==0.4.33->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 13)) (0.9.0)\r\nRequirement already satisfied: gitdb<5,>=4.0.1 in /databricks/python3/lib/python3.10/site-packages (from gitpython!=3.1.19->streamlit==1.18.1->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 2)) (4.0.10)\r\nRequirement already satisfied: zipp>=0.5 in /databricks/python3/lib/python3.10/site-packages (from importlib-metadata>=1.4->streamlit==1.18.1->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 2)) (3.8.0)\r\nRequirement already satisfied: PyJWT[crypto]<3,>=1.0.0 in /usr/lib/python3/dist-packages (from msal<2.0.0,>=1.7.0->azure-identity==1.6.0->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 1)) (2.3.0)\r\nCollecting portalocker<3,>=1.0\r\n  Using cached portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\r\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.10/site-packages (from requests>=2.4->streamlit==1.18.1->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 2)) (2022.9.14)\r\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.10/site-packages (from requests>=2.4->streamlit==1.18.1->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 2)) (3.3)\r\nCollecting markdown-it-py>=2.2.0\r\n  Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\r\nCollecting pygments<3.0.0,>=2.13.0\r\n  Using cached Pygments-2.16.1-py3-none-any.whl (1.2 MB)\r\nRequirement already satisfied: greenlet!=0.4.17 in /databricks/python3/lib/python3.10/site-packages (from SQLAlchemy<2,>=1->langchain==0.0.129->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 14)) (1.1.1)\r\nRequirement already satisfied: pycparser in /databricks/python3/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=2.1.4->azure-identity==1.6.0->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 1)) (2.21)\r\nRequirement already satisfied: smmap<6,>=3.0.1 in /databricks/python3/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19->streamlit==1.18.1->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 2)) (5.0.0)\r\nRequirement already satisfied: MarkupSafe>=0.23 in /databricks/python3/lib/python3.10/site-packages (from jinja2->altair>=3.2.0->streamlit==1.18.1->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 2)) (2.0.1)\r\nRequirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /databricks/python3/lib/python3.10/site-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit==1.18.1->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 2)) (0.18.0)\r\nCollecting mdurl~=0.1\r\n  Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\r\nRequirement already satisfied: mypy-extensions>=0.3.0 in /databricks/python3/lib/python3.10/site-packages (from typing-inspect>=0.4.0->dataclasses-json->llama-index==0.4.33->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 13)) (0.4.3)\r\nInstalling collected packages: faiss-cpu, watchdog, validators, tzlocal, toolz, toml, tenacity, semver, scipy, python-dotenv, pympler, pygments, pycryptodomex, portalocker, mdurl, lxml, contourpy, scikit-learn, pydeck, plotly, matplotlib, markdown-it-py, blobfile, tiktoken, rich, openai, altair, streamlit, msal, msal-extensions, langchain, llama-index, azure-identity\r\n  Attempting uninstall: tenacity\r\n    Found existing installation: tenacity 8.1.0\r\n    Not uninstalling tenacity at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-ed4309ed-8ab6-4df8-a06d-15fab14f0d59\r\n    Can't uninstall 'tenacity'. No files were found to uninstall.\r\n  Attempting uninstall: scipy\r\n    Found existing installation: scipy 1.9.1\r\n    Not uninstalling scipy at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-ed4309ed-8ab6-4df8-a06d-15fab14f0d59\r\n    Can't uninstall 'scipy'. No files were found to uninstall.\r\n  Attempting uninstall: pygments\r\n    Found existing installation: Pygments 2.11.2\r\n    Not uninstalling pygments at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-ed4309ed-8ab6-4df8-a06d-15fab14f0d59\r\n    Can't uninstall 'Pygments'. No files were found to uninstall.\r\n  Attempting uninstall: scikit-learn\r\n    Found existing installation: scikit-learn 1.1.1\r\n    Not uninstalling scikit-learn at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-ed4309ed-8ab6-4df8-a06d-15fab14f0d59\r\n    Can't uninstall 'scikit-learn'. No files were found to uninstall.\r\n  Attempting uninstall: plotly\r\n    Found existing installation: plotly 5.9.0\r\n    Not uninstalling plotly at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-ed4309ed-8ab6-4df8-a06d-15fab14f0d59\r\n    Can't uninstall 'plotly'. No files were found to uninstall.\r\n  Attempting uninstall: matplotlib\r\n    Found existing installation: matplotlib 3.5.2\r\n    Not uninstalling matplotlib at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-ed4309ed-8ab6-4df8-a06d-15fab14f0d59\r\n    Can't uninstall 'matplotlib'. No files were found to uninstall.\r\n  Attempting uninstall: tiktoken\r\n    Found existing installation: tiktoken 0.4.0\r\n    Not uninstalling tiktoken at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-ed4309ed-8ab6-4df8-a06d-15fab14f0d59\r\n    Can't uninstall 'tiktoken'. No files were found to uninstall.\r\n  Attempting uninstall: openai\r\n    Found existing installation: openai 0.27.7\r\n    Not uninstalling openai at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-ed4309ed-8ab6-4df8-a06d-15fab14f0d59\r\n    Can't uninstall 'openai'. No files were found to uninstall.\r\n  Attempting uninstall: langchain\r\n    Found existing installation: langchain 0.0.181\r\n    Not uninstalling langchain at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-ed4309ed-8ab6-4df8-a06d-15fab14f0d59\r\n    Can't uninstall 'langchain'. No files were found to uninstall.\r\n\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\ndatabricks-feature-store 0.13.5 requires pyspark<4,>=3.1.2, which is not installed.\r\nmleap 0.20.0 requires scikit-learn<0.23.0,>=0.22.0, but you have scikit-learn 1.2.0 which is incompatible.\u001B[0m\u001B[31m\r\n\u001B[0mSuccessfully installed altair-5.1.1 azure-identity-1.6.0 blobfile-2.0.2 contourpy-1.1.0 faiss-cpu-1.7.4 langchain-0.0.129 llama-index-0.4.33 lxml-4.9.3 markdown-it-py-3.0.0 matplotlib-3.6.3 mdurl-0.1.2 msal-1.23.0 msal-extensions-0.3.1 openai-0.27.8 plotly-5.12.0 portalocker-2.7.0 pycryptodomex-3.18.0 pydeck-0.8.1b0 pygments-2.16.1 pympler-1.0.1 python-dotenv-0.21.0 rich-13.5.2 scikit-learn-1.2.0 scipy-1.10.0 semver-3.0.1 streamlit-1.18.1 tenacity-8.2.3 tiktoken-0.3.0 toml-0.10.2 toolz-0.12.0 tzlocal-5.0.1 validators-0.21.2 watchdog-3.0.0\r\n\r\n\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip available: \u001B[0m\u001B[31;49m22.2.2\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.2.1\u001B[0m\r\n\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87a03523-86fb-4b36-abb1-cf6d11d16a3c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Set up Azure OpenAI\n",
    "load_dotenv()\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "openai.api_version = \"2022-12-01\"\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Define embedding model and encoding\n",
    "EMBEDDING_MODEL = 'text-embedding-ada-002'\n",
    "COMPLETION_MODEL = 'text-davinci-003'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7740db4e-8d9e-443a-9f3b-48190b06d74b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Provide Clear Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f60238d-eafc-4201-ae4c-6bd8499fdc1d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n\nIntroducing the newest addition to your hydration arsenal: the Super Hydration Water Bottle! This sleek and stylish water bottle is designed to keep you hydrated all day long. It features a double-walled stainless steel construction that keeps your drinks cold for up to 24 hours and hot for up to 12 hours. The wide mouth opening makes it easy to fill and clean, and the leak-proof lid ensures that your drinks stay where they belong. The Super Hydration Water Bottle is perfect for the gym, office, or anywhere else you need to stay hydrated. With its stylish design and superior insulation, you'll never have to worry about running out of water again!\n"
     ]
    }
   ],
   "source": [
    "response = openai.Completion.create(engine=\"text-davinci-003\",\n",
    "                                    prompt=\"write a product description for a new water bottle\",\n",
    "                                    temperature=0,\n",
    "                                    max_tokens=500)\n",
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7dc2d9e-add4-4c7b-b80f-199c8f6bff9b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n\nIntroducing the new 100% recycled water bottle! This bottle is made from recycled plastic, making it an eco-friendly choice for your hydration needs. It comes in natural colors with no dyes, so you can feel good about your purchase. Plus, with every purchase, 10 pounds of plastic are removed from our oceans, helping to reduce the amount of plastic pollution in our environment. The bottle is lightweight and durable, making it perfect for taking on the go. It also features a leak-proof lid and a wide mouth for easy filling and cleaning. Get your new 100% recycled water bottle today and help make a difference!\n"
     ]
    }
   ],
   "source": [
    "response = openai.Completion.create(engine=\"text-davinci-003\",\n",
    "                                    prompt=\"write a product description for a new water bottle that is 100% recycled. Be sure to include that it comes in natural colors with no dyes, and each purchase removed 10 pounds of plastic from our oceans\",\n",
    "                                    temperature=0,\n",
    "                                    max_tokens=1000)\n",
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "348573e4-06cf-42db-ba79-ad49dd856a04",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Section Markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b02026e-8a1d-4857-b276-d78e16b0e161",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n\nQuel temps va-t-il faire aujourd'hui ?\n"
     ]
    }
   ],
   "source": [
    "response = openai.Completion.create(engine=\"text-davinci-003\",\n",
    "                                    prompt=\"Translate the text into French --- What's the weather going to be like today? ---\",\n",
    "                                    temperature=0,\n",
    "                                    max_tokens=1000)\n",
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "18b43180-2852-4194-b513-9311490ce6dd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Primary and supporting content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b0b0d6d-a63b-4d66-9733-9bd953b7d1fa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n\n• Reinforcement learning is a type of machine learning that focuses on how intelligent agents should take actions in an environment to maximize rewards. \n• It is different from supervised learning in that it does not require labelled input/output pairs or explicit corrections of sub-optimal actions. \n• Reinforcement learning algorithms typically use dynamic programming techniques and do not assume knowledge of an exact mathematical model of the environment.\n"
     ]
    }
   ],
   "source": [
    "response = openai.Completion.create(engine=\"text-davinci-003\",\n",
    "                                    prompt=\"--- Reinforcement learning (RL) is an area of machine learning concerned with how intelligent agents ought to take actions in an environment in order to maximize the notion of cumulative reward. Reinforcement learning is one of three basic machine learning paradigms, alongside supervised learning and unsupervised learning. Reinforcement learning differs from supervised learning in not needing labelled input/output pairs to be presented, and in not needing sub-optimal actions to be explicitly corrected. Instead the focus is on finding a balance between exploration (of uncharted territory) and exploitation (of current knowledge).[1] The environment is typically stated in the form of a Markov decision process (MDP), because many reinforcement learning algorithms for this context use dynamic programming techniques.[2] The main difference between the classical dynamic programming methods and reinforcement learning algorithms is that the latter do not assume knowledge of an exact mathematical model of the MDP and they target large MDPs where exact methods become infeasible. --- Summarize this article and identify three takeaways in a bulleted fashion.\",\n",
    "                                    temperature=0,\n",
    "                                    max_tokens=1000)\n",
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0393593-2349-49c0-b1e6-b795b8f48ae0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n\n• Reinforcement learning (RL) is an area of machine learning concerned with how intelligent agents ought to take actions in an environment in order to maximize the notion of cumulative reward. \n• RL is one of three basic machine learning paradigms, alongside supervised learning and unsupervised learning. \n• RL differs from supervised learning in not needing labelled input/output pairs to be presented, and in not needing sub-optimal actions to be explicitly corrected. \n• The environment is typically stated in the form of a Markov decision process (MDP), because many reinforcement learning algorithms for this context use dynamic programming techniques. \n• The main difference between the classical dynamic programming methods and reinforcement learning algorithms is that the latter do not assume knowledge of an exact mathematical model of the MDP and they target large MDPs where exact methods become infeasible.\n"
     ]
    }
   ],
   "source": [
    "response = openai.Completion.create(engine=\"text-davinci-003\",\n",
    "                                    prompt=\"--- Reinforcement learning (RL) is an area of machine learning concerned with how intelligent agents ought to take actions in an environment in order to maximize the notion of cumulative reward. Reinforcement learning is one of three basic machine learning paradigms, alongside supervised learning and unsupervised learning. Reinforcement learning differs from supervised learning in not needing labelled input/output pairs to be presented, and in not needing sub-optimal actions to be explicitly corrected. Instead the focus is on finding a balance between exploration (of uncharted territory) and exploitation (of current knowledge).[1] The environment is typically stated in the form of a Markov decision process (MDP), because many reinforcement learning algorithms for this context use dynamic programming techniques.[2] The main difference between the classical dynamic programming methods and reinforcement learning algorithms is that the latter do not assume knowledge of an exact mathematical model of the MDP and they target large MDPs where exact methods become infeasible.  ---                                     \\\n",
    "                                    Topics I am very interested in includes AI, Pros to RL algorithms.00-explore-data\\\n",
    "                                    \\\n",
    "                                    Summarize this article and identify three takeaways in a bulleted fashion.\",\n",
    "                                    temperature=0,\n",
    "                                    max_tokens=1000)\n",
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a1408907-a7ad-4d72-a860-18034e653012",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Cues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d0a5911-169d-494b-878e-18fd59827262",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " customers.name, purchases.date\nFROM customers\nINNER JOIN purchases\nON customers.id = purchases.customer_id\nWHERE purchases.date > DATE_SUB(NOW(), INTERVAL 1 YEAR);\n"
     ]
    }
   ],
   "source": [
    "response = openai.Completion.create(engine=\"text-davinci-003\",\n",
    "                                    prompt=\"write a join query to get customer names with purchases in the past year. SELECT\",\n",
    "                                    temperature=0,\n",
    "                                    max_tokens=1000)\n",
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d6c8360e-1af7-4f1d-9e07-3e293dc404a2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Request Output Composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58771611-6f27-489c-92aa-39186b05ead8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n\n| Animal | Genus | Color |\n|-------|-------|-------|\n| Cat   | Felis | Grey  |\n| Dog   | Canis | Brown |\n| Horse | Equus | White |\n| Cow   | Bos   | Black |\n| Pig   | Sus   | Pink  |\n| Sheep | Ovis  | White |\n"
     ]
    }
   ],
   "source": [
    "response = openai.Completion.create(engine=\"text-davinci-003\",\n",
    "                                    prompt=\"Write a table in markdown with 6 animals in it, with their genus and color included.\",\n",
    "                                    temperature=0,\n",
    "                                    max_tokens=1000)\n",
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c344e0f-7738-4151-b747-143a17e2b299",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " You can insert fictional people or movie characters. E.g., {\"firstName\": \"Luke Skywalker\", \"job\": \"Jedi\"}¶\n\n[{\"firstName\": \"Harry Potter\", \"job\": \"Wizard\"},\n  {\"firstName\": \"Ron Weasley\", \"job\": \"Wizard\"},\n  {\"firstName\": \"Hermione Granger\", \"job\": \"Wizard\"},\n  {\"firstName\": \"Hagrid\", \"job\": \"Keeper of Keys and Grounds at Hogwarts\"},\n  {\"firstName\": \"Lucius Malfoy\", \"job\":\"Death Eater\"},\n  {\"firstName\": \"Moaning Myrtle\", \"job\":\"Ghost\"},\n  {\"firstName\": \"Percy Weasley\", \"job\": \"Ministry of Magic\"},\n  {\"firstName\": \"Gilderoy Lockhart\", \"job\": \"Prof. of Defense Against the Dark Arts\"},\n  {\"firstName\": \"Luna Lovegood\", \"job\": \"Hogwarts Student\"},\n  {\"firstName\": \"Fleur Delacour\", \"job\": \"Triwizard Champion\"},\n  {\"firstName\": \"Neville Longbottom\", \"job\": \"Hogwarts Student\"},\n  {\"firstName\": \"Severus Snape\", \"job\": \"Hogwarts Teacher\"}]\n\n**1.3**\nPut this people and their salaries into pandas Dataframe and calculate the salary with respect to taxes (35%). Or another formula you'd prefer.\n\nThe Dataframe should look like this:\n    \n    \n              firstName \t     job\t     salary\t    salaryWithTax\n       0 \t    Harry \t          Wizard\t 1000\t          650.00\n       1 \t    Ron \t          Wizard\t 1500\t          975.00\n       2 \t    Hermione \t  Wizard\t 1540       \t  1001.00\n       ...      ...             ...        ...              ...\n       \nEnsure, that the Names are in the alphabetical order.\n\nMake all names starts from upper case.\n\nAfter that, answer the questions:\n\n3.1 What profession is the most common among these people? \n3.2 Calculate the average salary? The median salary?\n\n(3.3. optional) Calculate the best salary? Who has it? The lowest salary?¶\n\n**1.4**\nVisualize: plot pie chart and hist plot based on DataFrame created above, add title for both graphs.\n\nMake 3 bars charts of average salary per profession, median salary per profession, and Salary with tax per profession. Add title and names of bars.\n\n**1.5**\nSave your Dataframe to csv-file named \"HW3_my_Salaries.csv\". Ensure that you don’t save the index in csv.\n\nZip your notebook with the file created above. And submit it.\n\n(3.6. optional) Upload the file you saved in the previous task to your Gitlab account.  Add a README.md file where you write an explanation of what the file contains and give an example of how the file can be used. The file should be uploaded to the newly created repository. Post a link to the repository. If you are new to git, please follow this brief instruction.\n\ndeadline: 11/10/2021\n\ntotal point: 7¶\n\nGrading criteria:\n    \ncorrect dataset creation (1 point)\nall df-meaningful columns have non-null values (1 points),\ncorrect DataFrame calculation (1 point),\ncorrect naming (1 point),\ncorrect data output (csv) (1 point),\n3 plots (2 point)\n\nthe correct answers to the questions (around 0.5 points for each question). If the solution is correct, but the code can be improved, -0.2 for each task.\n\ncognitive complexity is less than 5 (for each correct task - 0.2 points)\n\nminimal number of comments (for each correct task - 0.2 points)\n\nYou can get max 1.6 points bonus for additional tasks\n\n1.1 (0.2 point) \n\n1.2 (0.2 point)\n\n1.3 (up to 1.6 points)\n\n#### minimum score to pass - 3.5 points ###\n\n## Good luck! ##\n    \n\n\n---\n\n# Homework 3 (advanced)\n\n(3.6. optional) Upload the file you saved in the previous task to your Gitlab account.  Add a README.md file where you write an explanation of what the file contains and give an example of how the file can be used. The file should be uploaded to the newly created repository. Post a link to the repository. If you are new to git, please follow this instruction. \n\n***Hint:*** it is simply enough to upload content on http://gist.github.com\n\n\n(3.7. optional, max 2 points)\n- a) Create a scatter plot of this function $y = x^3 + 4$, in the interval `x = [-5, 5]`;\n- b) Create a bar plot containing undershoot and oversh\n"
     ]
    }
   ],
   "source": [
    "openai.api_version = \"2023-07-01-preview\"\n",
    "response = openai.Completion.create(engine=\"ChatGPT\",\n",
    "                                    prompt=\"Put fictional characters into JSON of the following format. {firstNameFIctional: jobFictional:}.\",\n",
    "                                    temperature=1,\n",
    "                                    max_tokens=1000)\n",
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fa870d2c-5ffa-455e-bc4f-3053ff11346f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Few Shot Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65e49ccf-5b44-4766-aeb1-7523cbc507b3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am a marketing writing assistant. I help come up with creative content ideas and content like marketing emails, blog posts, tweets, ad copy, and product descriptions.\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  engine=\"ChatGPT\",\n",
    "  messages = [{\"role\":\"system\",\"content\":\"You are a marketing writing assistant. You help come up with creative content ideas and content like marketing emails, blog posts, tweets, ad copy and product descriptions. You write in a friendly yet professional tone but can tailor your writing style that best works for a user-specified audience. If you do not know the answer to a question, respond by saying \\\"I do not know the answer to your question.\\\"\"},{\"role\":\"user\",\"content\":\"What type of assistant are you?\"}],\n",
    "  temperature=1,\n",
    "  max_tokens=400,\n",
    "  top_p=0.95,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0,\n",
    "  stop=None)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "18c0c248-d038-4a5d-8cd4-5a097d56caa3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Chain of thought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1d9dd78-66b3-42c0-b64e-9ea4b730371d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Many people believe that the sport of golf is the easiest to learn but hardest to master. The basic concept of hitting a ball into a hole seems simple enough, but mastering the various techniques and strategies involved in the game can take years of practice and dedication. Additionally, the mental aspect of the game, such as maintaining focus and managing emotions, can be challenging even for experienced players.\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  engine=\"ChatGPT\",\n",
    "  messages = [{\"role\":\"system\",\"content\":\"You are an AI assistant that helps people find information.\"},{\"role\":\"user\",\"content\":\"what sport is the easiest to learn but hardest to master?\"}],\n",
    "  temperature=0,\n",
    "  max_tokens=800,\n",
    "  top_p=0,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0,\n",
    "  stop=None)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bbbaceb7-da7d-4b6b-98c8-64e9f4c49aac",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When it comes to sports, there are many that can be easy to learn but difficult to master. However, one sport that stands out in this regard is golf. Here's a step-by-step approach to my thoughts:\n\nStep 1: Consider the basics of golf\nGolf is a sport that involves hitting a ball with a club into a series of holes on a course. The basic concept is simple enough to understand, and most people can learn the basics of the game relatively quickly.\n\nStep 2: Consider the difficulty of mastering golf\nHowever, mastering golf is an entirely different story. Golf requires a combination of physical skill, mental focus, and strategic thinking. It takes years of practice and dedication to become a truly skilled golfer.\n\nStep 3: Consider the factors that make golf difficult to master\nThere are several factors that make golf difficult to master. For one, the swing itself is incredibly complex, requiring precise timing, coordination, and technique. Additionally, the mental aspect of the game is just as important as the physical. Golfers must be able to stay focused and maintain their composure, even when facing difficult shots or challenging conditions.\n\nStep 4: Consider the factors that make golf easy to learn\nDespite its difficulty, golf is also relatively easy to learn. The basic mechanics of the swing can be taught in a relatively short amount of time, and beginners can start playing on a course almost immediately.\n\nStep 5: Conclusion\nTaking all of these factors into account, it's clear that golf is a sport that is easy to learn but hard to master. While the basics of the game can be picked up relatively quickly, becoming a truly skilled golfer takes years of practice and dedication.\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  engine=\"ChatGPT\",\n",
    "  messages = [{\"role\":\"system\",\"content\":\"You are an AI assistant that helps people find information.\"},{\"role\":\"user\",\"content\":\"what sport is the easiest to learn but hardest to master? Explain step-by-step approach of your thoughts, ending in your answer\"}],\n",
    "  temperature=0,\n",
    "  max_tokens=800,\n",
    "  top_p=0,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0,\n",
    "  stop=None)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dbb87a70-2861-4583-b599-cf7ff9ff6467",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "MODULE 5 - PROMPT ENGINEERING",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
