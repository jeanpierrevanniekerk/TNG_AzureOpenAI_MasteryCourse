{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fe7046c4-aea1-4353-8b38-07ea55dee35b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Extract Key Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc555da4-84fd-47e7-9433-cf41939532ec",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2e354b6d-b09c-4e44-9fbe-4989f314c3b3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Set up Azure OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf42c590-1834-4e34-85f2-5da4c6c3cc56",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting azure-identity==1.6.0\r\n  Using cached azure_identity-1.6.0-py2.py3-none-any.whl (108 kB)\r\nCollecting streamlit==1.18.1\r\n  Using cached streamlit-1.18.1-py2.py3-none-any.whl (9.6 MB)\r\nCollecting openai==0.27.8\r\n  Using cached openai-0.27.8-py3-none-any.whl (73 kB)\r\nCollecting python-dotenv==0.21.0\r\n  Using cached python_dotenv-0.21.0-py3-none-any.whl (18 kB)\r\nRequirement already satisfied: numpy in /databricks/python3/lib/python3.10/site-packages (from -r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 5)) (1.21.5)\r\nRequirement already satisfied: pandas in /databricks/python3/lib/python3.10/site-packages (from -r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 6)) (1.4.4)\r\nCollecting matplotlib==3.6.3\r\n  Using cached matplotlib-3.6.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.8 MB)\r\nCollecting plotly==5.12.0\r\n  Using cached plotly-5.12.0-py2.py3-none-any.whl (15.2 MB)\r\nCollecting scipy==1.10.0\r\n  Using cached scipy-1.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.4 MB)\r\nCollecting scikit-learn==1.2.0\r\n  Using cached scikit_learn-1.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.5 MB)\r\nRequirement already satisfied: tenacity in /databricks/python3/lib/python3.10/site-packages (from -r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 11)) (8.1.0)\r\nCollecting tiktoken==0.3.0\r\n  Using cached tiktoken-0.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\r\nCollecting llama-index==0.4.33\r\n  Using cached llama_index-0.4.33-py3-none-any.whl\r\nCollecting langchain==0.0.129\r\n  Using cached langchain-0.0.129-py3-none-any.whl (467 kB)\r\nCollecting faiss-cpu\r\n  Using cached faiss_cpu-1.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\r\nCollecting msal<2.0.0,>=1.7.0\r\n  Using cached msal-1.23.0-py2.py3-none-any.whl (90 kB)\r\nRequirement already satisfied: azure-core<2.0.0,>=1.0.0 in /databricks/python3/lib/python3.10/site-packages (from azure-identity==1.6.0->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 1)) (1.27.1)\r\nRequirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from azure-identity==1.6.0->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 1)) (1.16.0)\r\nRequirement already satisfied: cryptography>=2.1.4 in /databricks/python3/lib/python3.10/site-packages (from azure-identity==1.6.0->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 1)) (37.0.1)\r\nCollecting msal-extensions~=0.3.0\r\n  Using cached msal_extensions-0.3.1-py2.py3-none-any.whl (18 kB)\r\nCollecting watchdog\r\n  Using cached watchdog-3.0.0-py3-none-manylinux2014_x86_64.whl (82 kB)\r\nCollecting tzlocal>=1.1\r\n  Using cached tzlocal-5.0.1-py3-none-any.whl (20 kB)\r\nRequirement already satisfied: tornado>=6.0.3 in /databricks/python3/lib/python3.10/site-packages (from streamlit==1.18.1->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 2)) (6.1)\r\nRequirement already satisfied: protobuf<4,>=3.12 in /databricks/python3/lib/python3.10/site-packages (from streamlit==1.18.1->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 2)) (3.19.4)\r\nCollecting pydeck>=0.1.dev5\r\n  Using cached pydeck-0.8.1b0-py2.py3-none-any.whl (4.8 MB)\r\nCollecting validators>=0.2\r\n  Using cached validators-0.21.2-py3-none-any.whl (25 kB)\r\nRequirement already satisfied: click>=7.0 in /databricks/python3/lib/python3.10/site-packages (from streamlit==1.18.1->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 2)) (8.0.4)\r\nRequirement already satisfied: packaging>=14.1 in /databricks/python3/lib/python3.10/site-packages (from streamlit==1.18.1->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 2)) (21.3)\r\nRequirement already satisfied: cachetools>=4.0 in /databricks/python3/lib/python3.10/site-packages (from streamlit==1.18.1->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 2)) (4.2.4)\r\nRequirement already satisfied: requests>=2.4 in /databricks/python3/lib/python3.10/site-packages (from streamlit==1.18.1->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 2)) (2.28.1)\r\nCollecting rich>=10.11.0\r\n  Using cached rich-13.5.2-py3-none-any.whl (239 kB)\r\nCollecting pympler>=0.9\r\n  Using cached Pympler-1.0.1-py3-none-any.whl (164 kB)\r\nRequirement already satisfied: blinker>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit==1.18.1->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 2)) (1.4)\r\nRequirement already satisfied: gitpython!=3.1.19 in /databricks/python3/lib/python3.10/site-packages (from streamlit==1.18.1->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 2)) (3.1.27)\r\nRequirement already satisfied: pyarrow>=4.0 in /databricks/python3/lib/python3.10/site-packages (from streamlit==1.18.1->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 2)) (8.0.0)\r\nCollecting semver\r\n  Using cached semver-3.0.1-py3-none-any.whl (17 kB)\r\nCollecting toml\r\n  Using cached toml-0.10.2-py2.py3-none-any.whl (16 kB)\r\nRequirement already satisfied: python-dateutil in /databricks/python3/lib/python3.10/site-packages (from streamlit==1.18.1->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 2)) (2.8.2)\r\nRequirement already satisfied: pillow>=6.2.0 in /databricks/python3/lib/python3.10/site-packages (from streamlit==1.18.1->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 2)) (9.2.0)\r\nRequirement already satisfied: typing-extensions>=3.10.0.0 in /databricks/python3/lib/python3.10/site-packages (from streamlit==1.18.1->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 2)) (4.3.0)\r\nRequirement already satisfied: importlib-metadata>=1.4 in /databricks/python3/lib/python3.10/site-packages (from streamlit==1.18.1->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 2)) (4.11.3)\r\nCollecting altair>=3.2.0\r\n  Using cached altair-5.1.1-py3-none-any.whl (520 kB)\r\nRequirement already satisfied: aiohttp in /databricks/python3/lib/python3.10/site-packages (from openai==0.27.8->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 3)) (3.8.4)\r\nRequirement already satisfied: tqdm in /databricks/python3/lib/python3.10/site-packages (from openai==0.27.8->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 3)) (4.64.1)\r\nCollecting contourpy>=1.0.1\r\n  Using cached contourpy-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB)\r\nRequirement already satisfied: fonttools>=4.22.0 in /databricks/python3/lib/python3.10/site-packages (from matplotlib==3.6.3->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 7)) (4.25.0)\r\nRequirement already satisfied: pyparsing>=2.2.1 in /databricks/python3/lib/python3.10/site-packages (from matplotlib==3.6.3->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 7)) (3.0.9)\r\nRequirement already satisfied: kiwisolver>=1.0.1 in /databricks/python3/lib/python3.10/site-packages (from matplotlib==3.6.3->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 7)) (1.4.2)\r\nRequirement already satisfied: cycler>=0.10 in /databricks/python3/lib/python3.10/site-packages (from matplotlib==3.6.3->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 7)) (0.11.0)\r\nRequirement already satisfied: threadpoolctl>=2.0.0 in /databricks/python3/lib/python3.10/site-packages (from scikit-learn==1.2.0->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 10)) (2.2.0)\r\nRequirement already satisfied: joblib>=1.1.1 in /databricks/python3/lib/python3.10/site-packages (from scikit-learn==1.2.0->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 10)) (1.2.0)\r\nRequirement already satisfied: regex>=2022.1.18 in /databricks/python3/lib/python3.10/site-packages (from tiktoken==0.3.0->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 12)) (2022.7.9)\r\nCollecting blobfile>=2\r\n  Using cached blobfile-2.0.2-py3-none-any.whl (74 kB)\r\nCollecting tenacity\r\n  Using cached tenacity-8.2.3-py3-none-any.whl (24 kB)\r\nRequirement already satisfied: dataclasses-json in /databricks/python3/lib/python3.10/site-packages (from llama-index==0.4.33->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 13)) (0.5.8)\r\nRequirement already satisfied: SQLAlchemy<2,>=1 in /databricks/python3/lib/python3.10/site-packages (from langchain==0.0.129->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 14)) (1.4.39)\r\nRequirement already satisfied: PyYAML>=5.4.1 in /databricks/python3/lib/python3.10/site-packages (from langchain==0.0.129->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 14)) (6.0)\r\nRequirement already satisfied: pydantic<2,>=1 in /databricks/python3/lib/python3.10/site-packages (from langchain==0.0.129->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 14)) (1.10.6)\r\nRequirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.10/site-packages (from pandas->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 6)) (2022.1)\r\nRequirement already satisfied: multidict<7.0,>=4.5 in /databricks/python3/lib/python3.10/site-packages (from aiohttp->openai==0.27.8->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 3)) (6.0.4)\r\nRequirement already satisfied: frozenlist>=1.1.1 in /databricks/python3/lib/python3.10/site-packages (from aiohttp->openai==0.27.8->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 3)) (1.3.3)\r\nRequirement already satisfied: attrs>=17.3.0 in /databricks/python3/lib/python3.10/site-packages (from aiohttp->openai==0.27.8->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 3)) (21.4.0)\r\nRequirement already satisfied: yarl<2.0,>=1.0 in /databricks/python3/lib/python3.10/site-packages (from aiohttp->openai==0.27.8->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 3)) (1.9.2)\r\nRequirement already satisfied: aiosignal>=1.1.2 in /databricks/python3/lib/python3.10/site-packages (from aiohttp->openai==0.27.8->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 3)) (1.3.1)\r\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /databricks/python3/lib/python3.10/site-packages (from aiohttp->openai==0.27.8->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 3)) (2.0.4)\r\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /databricks/python3/lib/python3.10/site-packages (from aiohttp->openai==0.27.8->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 3)) (4.0.2)\r\nRequirement already satisfied: jinja2 in /databricks/python3/lib/python3.10/site-packages (from altair>=3.2.0->streamlit==1.18.1->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 2)) (2.11.3)\r\nRequirement already satisfied: jsonschema>=3.0 in /databricks/python3/lib/python3.10/site-packages (from altair>=3.2.0->streamlit==1.18.1->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 2)) (4.16.0)\r\nCollecting toolz\r\n  Using cached toolz-0.12.0-py3-none-any.whl (55 kB)\r\nRequirement already satisfied: filelock~=3.0 in /databricks/python3/lib/python3.10/site-packages (from blobfile>=2->tiktoken==0.3.0->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 12)) (3.6.0)\r\nCollecting pycryptodomex~=3.8\r\n  Using cached pycryptodomex-3.18.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\r\nCollecting lxml~=4.9\r\n  Using cached lxml-4.9.3-cp310-cp310-manylinux_2_28_x86_64.whl (7.9 MB)\r\nRequirement already satisfied: urllib3<3,>=1.25.3 in /databricks/python3/lib/python3.10/site-packages (from blobfile>=2->tiktoken==0.3.0->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 12)) (1.26.11)\r\nRequirement already satisfied: cffi>=1.12 in /databricks/python3/lib/python3.10/site-packages (from cryptography>=2.1.4->azure-identity==1.6.0->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 1)) (1.15.1)\r\nRequirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /databricks/python3/lib/python3.10/site-packages (from dataclasses-json->llama-index==0.4.33->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 13)) (1.5.1)\r\nRequirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /databricks/python3/lib/python3.10/site-packages (from dataclasses-json->llama-index==0.4.33->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 13)) (3.19.0)\r\nRequirement already satisfied: typing-inspect>=0.4.0 in /databricks/python3/lib/python3.10/site-packages (from dataclasses-json->llama-index==0.4.33->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 13)) (0.9.0)\r\nRequirement already satisfied: gitdb<5,>=4.0.1 in /databricks/python3/lib/python3.10/site-packages (from gitpython!=3.1.19->streamlit==1.18.1->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 2)) (4.0.10)\r\nRequirement already satisfied: zipp>=0.5 in /databricks/python3/lib/python3.10/site-packages (from importlib-metadata>=1.4->streamlit==1.18.1->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 2)) (3.8.0)\r\nRequirement already satisfied: PyJWT[crypto]<3,>=1.0.0 in /usr/lib/python3/dist-packages (from msal<2.0.0,>=1.7.0->azure-identity==1.6.0->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 1)) (2.3.0)\r\nCollecting portalocker<3,>=1.0\r\n  Using cached portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\r\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.10/site-packages (from requests>=2.4->streamlit==1.18.1->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 2)) (3.3)\r\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.10/site-packages (from requests>=2.4->streamlit==1.18.1->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 2)) (2022.9.14)\r\nCollecting pygments<3.0.0,>=2.13.0\r\n  Using cached Pygments-2.16.1-py3-none-any.whl (1.2 MB)\r\nCollecting markdown-it-py>=2.2.0\r\n  Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\r\nRequirement already satisfied: greenlet!=0.4.17 in /databricks/python3/lib/python3.10/site-packages (from SQLAlchemy<2,>=1->langchain==0.0.129->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 14)) (1.1.1)\r\nRequirement already satisfied: pycparser in /databricks/python3/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=2.1.4->azure-identity==1.6.0->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 1)) (2.21)\r\nRequirement already satisfied: smmap<6,>=3.0.1 in /databricks/python3/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19->streamlit==1.18.1->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 2)) (5.0.0)\r\nRequirement already satisfied: MarkupSafe>=0.23 in /databricks/python3/lib/python3.10/site-packages (from jinja2->altair>=3.2.0->streamlit==1.18.1->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 2)) (2.0.1)\r\nRequirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /databricks/python3/lib/python3.10/site-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit==1.18.1->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 2)) (0.18.0)\r\nCollecting mdurl~=0.1\r\n  Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\r\nRequirement already satisfied: mypy-extensions>=0.3.0 in /databricks/python3/lib/python3.10/site-packages (from typing-inspect>=0.4.0->dataclasses-json->llama-index==0.4.33->-r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt (line 13)) (0.4.3)\r\nInstalling collected packages: faiss-cpu, watchdog, validators, tzlocal, toolz, toml, tenacity, semver, scipy, python-dotenv, pympler, pygments, pycryptodomex, portalocker, mdurl, lxml, contourpy, scikit-learn, pydeck, plotly, matplotlib, markdown-it-py, blobfile, tiktoken, rich, openai, altair, streamlit, msal, msal-extensions, langchain, llama-index, azure-identity\r\n  Attempting uninstall: tenacity\r\n    Found existing installation: tenacity 8.1.0\r\n    Not uninstalling tenacity at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-14596729-782a-4eca-b7df-c141200bb5a4\r\n    Can't uninstall 'tenacity'. No files were found to uninstall.\r\n  Attempting uninstall: scipy\r\n    Found existing installation: scipy 1.9.1\r\n    Not uninstalling scipy at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-14596729-782a-4eca-b7df-c141200bb5a4\r\n    Can't uninstall 'scipy'. No files were found to uninstall.\r\n  Attempting uninstall: pygments\r\n    Found existing installation: Pygments 2.11.2\r\n    Not uninstalling pygments at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-14596729-782a-4eca-b7df-c141200bb5a4\r\n    Can't uninstall 'Pygments'. No files were found to uninstall.\r\n  Attempting uninstall: scikit-learn\r\n    Found existing installation: scikit-learn 1.1.1\r\n    Not uninstalling scikit-learn at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-14596729-782a-4eca-b7df-c141200bb5a4\r\n    Can't uninstall 'scikit-learn'. No files were found to uninstall.\r\n  Attempting uninstall: plotly\r\n    Found existing installation: plotly 5.9.0\r\n    Not uninstalling plotly at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-14596729-782a-4eca-b7df-c141200bb5a4\r\n    Can't uninstall 'plotly'. No files were found to uninstall.\r\n  Attempting uninstall: matplotlib\r\n    Found existing installation: matplotlib 3.5.2\r\n    Not uninstalling matplotlib at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-14596729-782a-4eca-b7df-c141200bb5a4\r\n    Can't uninstall 'matplotlib'. No files were found to uninstall.\r\n  Attempting uninstall: tiktoken\r\n    Found existing installation: tiktoken 0.4.0\r\n    Not uninstalling tiktoken at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-14596729-782a-4eca-b7df-c141200bb5a4\r\n    Can't uninstall 'tiktoken'. No files were found to uninstall.\r\n  Attempting uninstall: openai\r\n    Found existing installation: openai 0.27.7\r\n    Not uninstalling openai at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-14596729-782a-4eca-b7df-c141200bb5a4\r\n    Can't uninstall 'openai'. No files were found to uninstall.\r\n  Attempting uninstall: langchain\r\n    Found existing installation: langchain 0.0.181\r\n    Not uninstalling langchain at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-14596729-782a-4eca-b7df-c141200bb5a4\r\n    Can't uninstall 'langchain'. No files were found to uninstall.\r\n\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\ndatabricks-feature-store 0.13.5 requires pyspark<4,>=3.1.2, which is not installed.\r\nmleap 0.20.0 requires scikit-learn<0.23.0,>=0.22.0, but you have scikit-learn 1.2.0 which is incompatible.\u001B[0m\u001B[31m\r\n\u001B[0mSuccessfully installed altair-5.1.1 azure-identity-1.6.0 blobfile-2.0.2 contourpy-1.1.0 faiss-cpu-1.7.4 langchain-0.0.129 llama-index-0.4.33 lxml-4.9.3 markdown-it-py-3.0.0 matplotlib-3.6.3 mdurl-0.1.2 msal-1.23.0 msal-extensions-0.3.1 openai-0.27.8 plotly-5.12.0 portalocker-2.7.0 pycryptodomex-3.18.0 pydeck-0.8.1b0 pygments-2.16.1 pympler-1.0.1 python-dotenv-0.21.0 rich-13.5.2 scikit-learn-1.2.0 scipy-1.10.0 semver-3.0.1 streamlit-1.18.1 tenacity-8.2.3 tiktoken-0.3.0 toml-0.10.2 toolz-0.12.0 tzlocal-5.0.1 validators-0.21.2 watchdog-3.0.0\r\n\r\n\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip available: \u001B[0m\u001B[31;49m22.2.2\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.2.1\u001B[0m\r\n\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -r /Workspace/Repos/jeanpierre.vanniekerk@truenorthgroup.co.za/document-analysis-using-gpt-3.ide/notebooks/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8771a2d6-8b27-4afe-9f2a-26f1342726b6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Set up Azure OpenAI\n",
    "load_dotenv()\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "openai.api_version = \"2022-12-01\"\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3b5ff405-c69a-4bd4-8886-6b20b38b095f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86dc7f6a-e311-4fdd-b3b1-1bc33c1cabb6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = spark.sql('select * from openai.bbc_news_data').limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c93d7850-6af3-4a01-a08d-7ed0ed6731ca",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Request to API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3fc4e95e-e074-4485-b4a2-a408e73ffccf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n  Extract key information from this text\nAd sales boost Time Warner profit\n\" Quarterly profits at US media giant TimeWarner jumped 76% to $1.13bn (Â£600m) for the three months to December, from $639m year-earlier.  The firm, which is now one of the biggest investors in Google, benefited from sales of high-speed internet connections and higher advert sales. TimeWarner said fourth quarter sales rose 2% to $11.1bn from $10.9bn. Its profits were buoyed by one-off gains which offset a profit dip at Warner Bros, and less users for AOL.  Time Warner said on Friday that it now owns 8% of search-engine Google. But its own internet business, AOL, had has mixed fortunes. It lost 464,000 subscribers in the fourth quarter profits were lower than in the preceding three quarters. However, the company said AOL's underlying profit before exceptional items rose 8% on the back of stronger internet advertising revenues. It hopes to increase subscribers by offering the online service free to TimeWarner internet customers and will try to sign up AOL's existing customers for high-speed broadband. TimeWarner also has to restate 2000 and 2003 results following a probe by the US Securities Exchange Commission (SEC), which is close to concluding.  Time Warner's fourth quarter profits were slightly better than analysts' expectations. But its film division saw profits slump 27% to $284m, helped by box-office flops Alexander and Catwoman, a sharp contrast to year-earlier, when the third and final film in the Lord of the Rings trilogy boosted results. For the full-year, TimeWarner posted a profit of $3.36bn, up 27% from its 2003 performance, while revenues grew 6.4% to $42.09bn. \"\"Our financial performance was strong, meeting or exceeding all of our full-year objectives and greatly enhancing our flexibility,\"\" chairman and chief executive Richard Parsons said. For 2005, TimeWarner is projecting operating earnings growth of around 5%, and also expects higher revenue and wider profit margins.  TimeWarner is to restate its accounts as part of efforts to resolve an inquiry into AOL by US market regulators. It has already offered to pay $300m to settle charges, in a deal that is under review by the SEC. The company said it was unable to estimate the amount it needed to set aside for legal reserves, which it previously set at $500m. It intends to adjust the way it accounts for a deal with German music publisher Bertelsmann's purchase of a stake in AOL Europe, which it had reported as advertising revenue. It will now book the sale of its stake in AOL Europe as a loss on the value of that stake. \"\n"
     ]
    }
   ],
   "source": [
    "# create prompt\n",
    "prompt_prefix = \"\"\" \n",
    "  Extract key information from this text\n",
    "\"\"\"\n",
    "\n",
    "prompt = prompt_prefix + df['title'].loc[0] + \"\\n\" + df['content'].loc[0]\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b604d9b-7247-49a6-9fc1-ae0bfebe760c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n\nKey Information: \n- Time Warner's quarterly profits increased 76% to $1.13bn for the three months to December, from $639m year-earlier\n- Sales rose 2% to $11.1bn from $10.9bn in fourth quarter\n- Profits were buoyed by one-off gains which offset a profit dip at Warner Bros and less users for AOL \n- Owns 8% of Google \n- AOL lost 464,000 subscribers in fourth quarter but underlying profit before exceptional items rose 8% on back of stronger internet advertising revenues \n- Film division saw profits slump 27%, helped by box office flops Alexander and Catwoman  \n- Full year profits up 27%, revenue grew 6.4% to $42.09bn \n- Projecting operating earnings growth of around 5%, higher revenue and wider profit margins in 2005  \n- To restate accounts as part of efforts to resolve inquiry into AOL by US market regulators; offered to pay $300m settlement\n"
     ]
    }
   ],
   "source": [
    "# Request API\n",
    "response = openai.Completion.create(\n",
    "  deployment_id=\"text-davinci-003\", \n",
    "  prompt=prompt,\n",
    "  temperature=0,\n",
    "  max_tokens=1000,\n",
    "  top_p=0.95,\n",
    "  frequency_penalty=1,\n",
    "  presence_penalty=1\n",
    ")\n",
    "\n",
    "# print response\n",
    "print(response['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36810187-6340-4828-a981-812e198b2808",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "colname = 'key_info'\n",
    "results = pd.DataFrame(columns=[colname], index=df.index)\n",
    "\n",
    "prompt_prefix = \"\"\" \n",
    "  Extract key information from this text\n",
    "\"\"\"\n",
    "\n",
    "for idx, title, content in zip(df.index.values, df['title'].loc[df.index.values], df['content'].loc[df.index.values]):\n",
    "  \n",
    "  # build prompt\n",
    "  prompt = prompt_prefix + title + \"\\n\" + content\n",
    "\n",
    "  try:\n",
    "    # Request API\n",
    "    response = openai.Completion.create(\n",
    "      deployment_id=\"text-davinci-003\", \n",
    "      prompt=prompt,\n",
    "      temperature=0,\n",
    "      max_tokens=1000,\n",
    "      top_p=0.95,\n",
    "      frequency_penalty=1,\n",
    "      presence_penalty=1\n",
    "    )\n",
    "\n",
    "      # response\n",
    "    results[colname].loc[idx] = response['choices'][0]['text']\n",
    "  except Exception as err:\n",
    "    idx\n",
    "    print(f\"Unexpected {err=}, {type(err)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc11a1cf-b656-48da-ad77-b3d7605ee55c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(10, 6)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>filename</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>embedding</th>\n",
       "      <th>key_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>001.txt</td>\n",
       "      <td>Ad sales boost Time Warner profit</td>\n",
       "      <td>\" Quarterly profits at US media giant TimeWarn...</td>\n",
       "      <td>[-0.0012276918860152364, 0.00733763724565506, ...</td>\n",
       "      <td>\\n\\nKey Information: \\n- Time Warner's quarter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>002.txt</td>\n",
       "      <td>Dollar gains on Greenspan speech</td>\n",
       "      <td>\" The dollar has hit its highest level against...</td>\n",
       "      <td>[0.0009311728645116091, 0.014099937863647938, ...</td>\n",
       "      <td>\\n\\nKey Information: \\n- Dollar has hit highes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business</td>\n",
       "      <td>003.txt</td>\n",
       "      <td>Yukos unit buyer faces loan claim</td>\n",
       "      <td>\" The owners of embattled Russian oil giant Yu...</td>\n",
       "      <td>[-0.010487922467291355, 0.009665092453360558, ...</td>\n",
       "      <td>\\n\\nKey Information: \\n- Menatep Group is aski...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business</td>\n",
       "      <td>004.txt</td>\n",
       "      <td>High fuel prices hit BA's profits</td>\n",
       "      <td>\" British Airways has blamed high fuel prices ...</td>\n",
       "      <td>[0.0111119095236063, 0.004624682944267988, -0....</td>\n",
       "      <td>\\n\\nKey Information: \\n- British Airways profi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>business</td>\n",
       "      <td>005.txt</td>\n",
       "      <td>Pernod takeover talk lifts Domecq</td>\n",
       "      <td>Shares in UK drinks and food firm Allied Dome...</td>\n",
       "      <td>[-0.0021637482568621635, 0.005410161800682545,...</td>\n",
       "      <td>\\n\\nKey Information: \\n- Pernod Ricard is cons...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>business</td>\n",
       "      <td>006.txt</td>\n",
       "      <td>Japan narrowly escapes recession</td>\n",
       "      <td>\" Japan's economy teetered on the brink of a t...</td>\n",
       "      <td>[0.002582279033958912, 0.008218934759497643, -...</td>\n",
       "      <td>\\n\\nKey Information: \\n- Japan's economy grew ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>business</td>\n",
       "      <td>007.txt</td>\n",
       "      <td>Jobs growth still slow in the US</td>\n",
       "      <td>\" The US created fewer jobs than expected in J...</td>\n",
       "      <td>[0.005617379676550627, 0.005877326242625713, -...</td>\n",
       "      <td>\\n\\nKey Information: \\n- US firms added 146,00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>business</td>\n",
       "      <td>008.txt</td>\n",
       "      <td>India calls for fair trade rules</td>\n",
       "      <td>\" India, which attends the G7 meeting of seven...</td>\n",
       "      <td>[0.00015200248162727803, 0.0035213909577578306...</td>\n",
       "      <td>\\n\\nKey Information: \\n- India attends G7 meet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>business</td>\n",
       "      <td>009.txt</td>\n",
       "      <td>Ethiopia's crop production up 24%</td>\n",
       "      <td>\" Ethiopia produced 14.27 million tonnes of cr...</td>\n",
       "      <td>[0.008323440328240395, 0.014594526030123234, -...</td>\n",
       "      <td>\\n\\nKey Information: \\n- Ethiopia produced 14....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>business</td>\n",
       "      <td>010.txt</td>\n",
       "      <td>Court rejects $280bn tobacco case</td>\n",
       "      <td>A US government claim accusing the country's ...</td>\n",
       "      <td>[-0.0033349236473441124, 0.014696489088237286,...</td>\n",
       "      <td>\\n\\nKey Information: \\n- US government claim a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category  ...                                           key_info\n",
       "0  business  ...  \\n\\nKey Information: \\n- Time Warner's quarter...\n",
       "1  business  ...  \\n\\nKey Information: \\n- Dollar has hit highes...\n",
       "2  business  ...  \\n\\nKey Information: \\n- Menatep Group is aski...\n",
       "3  business  ...  \\n\\nKey Information: \\n- British Airways profi...\n",
       "4  business  ...  \\n\\nKey Information: \\n- Pernod Ricard is cons...\n",
       "5  business  ...  \\n\\nKey Information: \\n- Japan's economy grew ...\n",
       "6  business  ...  \\n\\nKey Information: \\n- US firms added 146,00...\n",
       "7  business  ...  \\n\\nKey Information: \\n- India attends G7 meet...\n",
       "8  business  ...  \\n\\nKey Information: \\n- Ethiopia produced 14....\n",
       "9  business  ...  \\n\\nKey Information: \\n- US government claim a...\n",
       "\n",
       "[10 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = pd.concat([df, results], axis=1)\n",
    "df_results.shape\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "03c0db18-1637-4e24-a544-b53cc7fb1490",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c201d817-f8f1-422f-a174-bb14c40c4541",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>filename</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>embedding</th>\n",
       "      <th>n_tokens</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>232.txt</td>\n",
       "      <td>Connick Jr to lead Broadway show</td>\n",
       "      <td>\" Singer and actor Harry Connick Jr is to star...</td>\n",
       "      <td>[-0.0013730002101510763, -0.03857267275452614,...</td>\n",
       "      <td>254</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>236.txt</td>\n",
       "      <td>Franz Ferdinand's art school lesson</td>\n",
       "      <td>\" Scottish rock band Franz Ferdinand, who shot...</td>\n",
       "      <td>[-0.00918667670339346, 0.002770294900983572, 0...</td>\n",
       "      <td>694</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>238.txt</td>\n",
       "      <td>Portishead back after eight years</td>\n",
       "      <td>\" Cult British group Portishead have revealed ...</td>\n",
       "      <td>[-0.01821870543062687, -0.02119753137230873, -...</td>\n",
       "      <td>329</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>240.txt</td>\n",
       "      <td>Elvis 'set for chart hat-trick'</td>\n",
       "      <td>The late US legend Elvis Presley is likely to...</td>\n",
       "      <td>[-0.02780121937394142, -0.010392170399427414, ...</td>\n",
       "      <td>318</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>243.txt</td>\n",
       "      <td>Blue beat U2 to top France honour</td>\n",
       "      <td>\" Irish band U2 have been honoured at France's...</td>\n",
       "      <td>[-0.021403657272458076, -0.013215591199696064,...</td>\n",
       "      <td>249</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>244.txt</td>\n",
       "      <td>Ten-year tragedy of missing Manic</td>\n",
       "      <td>\" Richey Edwards, guitarist and lyricist for T...</td>\n",
       "      <td>[-0.014232789166271687, 0.020377222448587418, ...</td>\n",
       "      <td>829</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>250.txt</td>\n",
       "      <td>Prince crowned 'top music earner'</td>\n",
       "      <td>\" Prince earned more than any other pop star i...</td>\n",
       "      <td>[0.0012800436234101653, -0.03181799128651619, ...</td>\n",
       "      <td>352</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>256.txt</td>\n",
       "      <td>Brits debate over 'urban' music</td>\n",
       "      <td>\" Joss Stone, a 17-year-old soul singer from D...</td>\n",
       "      <td>[-0.0016374018741771579, -0.010487286373972893...</td>\n",
       "      <td>2916</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>260.txt</td>\n",
       "      <td>Singer Christina Aguilera to wed</td>\n",
       "      <td>\" Pop star Christina Aguilera is to marry musi...</td>\n",
       "      <td>[-0.014513788744807243, -0.012519126757979393,...</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>264.txt</td>\n",
       "      <td>Grammys honour soul star Charles</td>\n",
       "      <td>\" The memory of soul legend Ray Charles domina...</td>\n",
       "      <td>[-0.013948743231594563, -0.005762143991887569,...</td>\n",
       "      <td>716</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category filename  ... n_tokens prediction\n",
       "0         1  232.txt  ...      254          1\n",
       "1         1  236.txt  ...      694          1\n",
       "2         1  238.txt  ...      329          1\n",
       "3         1  240.txt  ...      318          1\n",
       "4         1  243.txt  ...      249          1\n",
       "5         1  244.txt  ...      829          1\n",
       "6         1  250.txt  ...      352          1\n",
       "7         1  256.txt  ...     2916          1\n",
       "8         1  260.txt  ...      256          1\n",
       "9         1  264.txt  ...      716          1\n",
       "\n",
       "[10 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = spark.createDataFrame(df_results)\n",
    "df_results.write.mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(\"openai.document_analysis_key_information\")\n",
    "df_results = spark.sql('select * from openai.document_analysis_predictions')\n",
    "df_results.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d89b5857-0400-41d6-b33a-b0e5b5dcd250",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "735"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.cache().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2de411ec-97ac-48b3-a9e1-746c21c1d7f1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "MODULE 12 - KEY INFORMATION",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "azureml_py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6d65a8c07f5b6469e0fc613f182488c0dccce05038bbda39e5ac9075c0454d11"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
